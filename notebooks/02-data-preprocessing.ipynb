{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06f9af0e",
   "metadata": {},
   "source": [
    "# Data Preprocessing for Hepatitis C Prediction\n",
    "\n",
    "This notebook handles data cleaning, feature engineering, and preparation for machine learning. We'll transform the raw data into a format suitable for neural network training.\n",
    "\n",
    "## Objectives\n",
    "- Clean and handle missing values\n",
    "- Encode categorical variables  \n",
    "- Scale numerical features\n",
    "- Split data into train/test sets\n",
    "- Save processed data for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "428a2321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "sys.path.append('../src')\n",
    "from data import load_raw_data, clean_data, prepare_features, split_and_scale_data\n",
    "\n",
    "print(\"Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069571ec",
   "metadata": {},
   "source": [
    "## 1. Load and Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1670dcf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully: (615, 14)\n",
      "Raw data loaded successfully\n",
      "Data cleaned successfully\n",
      "Healthy: 540 samples\n",
      "Hepatitis C: 75 samples\n",
      "Cleaned data shape: (615, 16)\n",
      "Target distribution:\n",
      "target\n",
      "0    540\n",
      "1     75\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = load_raw_data('../data/raw/hepatitis_data.csv')\n",
    "\n",
    "if df is not None:\n",
    "    print(\"Raw data loaded successfully\")\n",
    "    \n",
    "    cleaned_data, sex_encoder = clean_data(df)\n",
    "    \n",
    "    if cleaned_data is not None:\n",
    "        print(f\"Cleaned data shape: {cleaned_data.shape}\")\n",
    "        print(f\"Target distribution:\")\n",
    "        print(cleaned_data['target'].value_counts())\n",
    "    else:\n",
    "        print(\"Data cleaning failed\")\n",
    "else:\n",
    "    print(\"Failed to load data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a55cc64",
   "metadata": {},
   "source": [
    "## 2. Prepare Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9dd07e02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features prepared: (615, 12)\n",
      "Missing values after imputation: 0\n",
      "Features prepared: (615, 12)\n",
      "Feature columns: ['Age', 'ALB', 'ALP', 'ALT', 'AST', 'BIL', 'CHE', 'CHOL', 'CREA', 'GGT', 'PROT', 'sex_encoded']\n",
      "Target distribution: {0: 540, 1: 75}\n",
      "\n",
      "Feature Summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>ALB</th>\n",
       "      <th>ALP</th>\n",
       "      <th>ALT</th>\n",
       "      <th>AST</th>\n",
       "      <th>BIL</th>\n",
       "      <th>CHE</th>\n",
       "      <th>CHOL</th>\n",
       "      <th>CREA</th>\n",
       "      <th>GGT</th>\n",
       "      <th>PROT</th>\n",
       "      <th>sex_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>615.000000</td>\n",
       "      <td>615.000000</td>\n",
       "      <td>615.000000</td>\n",
       "      <td>615.000000</td>\n",
       "      <td>615.000000</td>\n",
       "      <td>615.000000</td>\n",
       "      <td>615.000000</td>\n",
       "      <td>615.000000</td>\n",
       "      <td>615.000000</td>\n",
       "      <td>615.000000</td>\n",
       "      <td>615.000000</td>\n",
       "      <td>615.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>47.408130</td>\n",
       "      <td>41.620732</td>\n",
       "      <td>68.222927</td>\n",
       "      <td>28.441951</td>\n",
       "      <td>34.786341</td>\n",
       "      <td>11.396748</td>\n",
       "      <td>8.196634</td>\n",
       "      <td>5.366992</td>\n",
       "      <td>81.287805</td>\n",
       "      <td>39.533171</td>\n",
       "      <td>72.044390</td>\n",
       "      <td>0.613008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>10.055105</td>\n",
       "      <td>5.775935</td>\n",
       "      <td>25.646364</td>\n",
       "      <td>25.449889</td>\n",
       "      <td>33.090690</td>\n",
       "      <td>19.673150</td>\n",
       "      <td>2.205657</td>\n",
       "      <td>1.123499</td>\n",
       "      <td>49.756166</td>\n",
       "      <td>54.661071</td>\n",
       "      <td>5.398238</td>\n",
       "      <td>0.487458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>19.000000</td>\n",
       "      <td>14.900000</td>\n",
       "      <td>11.300000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>10.600000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.420000</td>\n",
       "      <td>1.430000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>44.800000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>39.000000</td>\n",
       "      <td>38.800000</td>\n",
       "      <td>52.950000</td>\n",
       "      <td>16.400000</td>\n",
       "      <td>21.600000</td>\n",
       "      <td>5.300000</td>\n",
       "      <td>6.935000</td>\n",
       "      <td>4.620000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>15.700000</td>\n",
       "      <td>69.300000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>47.000000</td>\n",
       "      <td>41.950000</td>\n",
       "      <td>66.200000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>25.900000</td>\n",
       "      <td>7.300000</td>\n",
       "      <td>8.260000</td>\n",
       "      <td>5.300000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>23.300000</td>\n",
       "      <td>72.200000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>54.000000</td>\n",
       "      <td>45.200000</td>\n",
       "      <td>79.300000</td>\n",
       "      <td>33.050000</td>\n",
       "      <td>32.900000</td>\n",
       "      <td>11.200000</td>\n",
       "      <td>9.590000</td>\n",
       "      <td>6.055000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>40.200000</td>\n",
       "      <td>75.400000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>77.000000</td>\n",
       "      <td>82.200000</td>\n",
       "      <td>416.600000</td>\n",
       "      <td>325.300000</td>\n",
       "      <td>324.000000</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>16.410000</td>\n",
       "      <td>9.670000</td>\n",
       "      <td>1079.100000</td>\n",
       "      <td>650.900000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Age         ALB         ALP         ALT         AST         BIL  \\\n",
       "count  615.000000  615.000000  615.000000  615.000000  615.000000  615.000000   \n",
       "mean    47.408130   41.620732   68.222927   28.441951   34.786341   11.396748   \n",
       "std     10.055105    5.775935   25.646364   25.449889   33.090690   19.673150   \n",
       "min     19.000000   14.900000   11.300000    0.900000   10.600000    0.800000   \n",
       "25%     39.000000   38.800000   52.950000   16.400000   21.600000    5.300000   \n",
       "50%     47.000000   41.950000   66.200000   23.000000   25.900000    7.300000   \n",
       "75%     54.000000   45.200000   79.300000   33.050000   32.900000   11.200000   \n",
       "max     77.000000   82.200000  416.600000  325.300000  324.000000  254.000000   \n",
       "\n",
       "              CHE        CHOL         CREA         GGT        PROT  \\\n",
       "count  615.000000  615.000000   615.000000  615.000000  615.000000   \n",
       "mean     8.196634    5.366992    81.287805   39.533171   72.044390   \n",
       "std      2.205657    1.123499    49.756166   54.661071    5.398238   \n",
       "min      1.420000    1.430000     8.000000    4.500000   44.800000   \n",
       "25%      6.935000    4.620000    67.000000   15.700000   69.300000   \n",
       "50%      8.260000    5.300000    77.000000   23.300000   72.200000   \n",
       "75%      9.590000    6.055000    88.000000   40.200000   75.400000   \n",
       "max     16.410000    9.670000  1079.100000  650.900000   90.000000   \n",
       "\n",
       "       sex_encoded  \n",
       "count   615.000000  \n",
       "mean      0.613008  \n",
       "std       0.487458  \n",
       "min       0.000000  \n",
       "25%       0.000000  \n",
       "50%       1.000000  \n",
       "75%       1.000000  \n",
       "max       1.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if 'cleaned_data' in locals() and cleaned_data is not None:\n",
    "    X, y, imputer = prepare_features(cleaned_data)\n",
    "    \n",
    "    if X is not None:\n",
    "        print(f\"Features prepared: {X.shape}\")\n",
    "        print(f\"Feature columns: {list(X.columns)}\")\n",
    "        print(f\"Target distribution: {y.value_counts().to_dict()}\")\n",
    "        \n",
    "        print(\"\\nFeature Summary:\")\n",
    "        display(X.describe())\n",
    "    else:\n",
    "        print(\"Feature preparation failed\")\n",
    "else:\n",
    "    print(\"No cleaned data available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773373fb",
   "metadata": {},
   "source": [
    "## 3. Split and Scale Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2bf3f8e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Data split and scaled:\n",
      "   Training set: (492, 12)\n",
      "   Test set: (123, 12)\n",
      "Data split and scaled successfully!\n",
      "Training features shape: (492, 12)\n",
      "Test features shape: (123, 12)\n",
      "Training targets shape: (492,)\n",
      "Test targets shape: (123,)\n",
      "\n",
      "Training set class distribution:\n",
      "  Healthy: 432 (87.8%)\n",
      "  Hepatitis C: 60 (12.2%)\n",
      "\n",
      "Test set class distribution:\n",
      "  Healthy: 108 (87.8%)\n",
      "  Hepatitis C: 15 (12.2%)\n"
     ]
    }
   ],
   "source": [
    "if 'X' in locals() and X is not None:\n",
    "    X_train, X_test, y_train, y_test, scaler = split_and_scale_data(X, y)\n",
    "    \n",
    "    print(\"Data split and scaled successfully!\")\n",
    "    print(f\"Training features shape: {X_train.shape}\")\n",
    "    print(f\"Test features shape: {X_test.shape}\")\n",
    "    print(f\"Training targets shape: {y_train.shape}\")\n",
    "    print(f\"Test targets shape: {y_test.shape}\")\n",
    "    \n",
    "    # Check class distribution in splits\n",
    "    print(f\"\\nTraining set class distribution:\")\n",
    "    print(f\"  Healthy: {sum(y_train == 0)} ({sum(y_train == 0)/len(y_train)*100:.1f}%)\")\n",
    "    print(f\"  Hepatitis C: {sum(y_train == 1)} ({sum(y_train == 1)/len(y_train)*100:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\nTest set class distribution:\")\n",
    "    print(f\"  Healthy: {sum(y_test == 0)} ({sum(y_test == 0)/len(y_test)*100:.1f}%)\")\n",
    "    print(f\"  Hepatitis C: {sum(y_test == 1)} ({sum(y_test == 1)/len(y_test)*100:.1f}%)\")\n",
    "else:\n",
    "    print(\"No features available for splitting\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108a946d",
   "metadata": {},
   "source": [
    "## 4. Save Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "28c941d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not all variables are available for saving\n"
     ]
    }
   ],
   "source": [
    "if all(var in locals() for var in ['X_train', 'X_test', 'y_train', 'y_test', 'scaler', 'imputer', 'sex_encoder']):\n",
    "    \n",
    "    os.makedirs('../data/processed', exist_ok=True)\n",
    "    \n",
    "    np.save('../data/processed/X_train.npy', X_train)\n",
    "    np.save('../data/processed/X_test.npy', X_test)\n",
    "    np.save('../data/processed/y_train.npy', y_train)\n",
    "    np.save('../data/processed/y_test.npy', y_test)\n",
    "    \n",
    "    preprocessing_info = {\n",
    "        'scaler': scaler,\n",
    "        'imputer': imputer,\n",
    "        'sex_encoder': sex_encoder,\n",
    "        'feature_names': list(X.columns),\n",
    "        'n_features': X.shape[1],\n",
    "        'n_samples_train': len(y_train),\n",
    "        'n_samples_test': len(y_test)\n",
    "    }\n",
    "    \n",
    "    with open('../data/processed/preprocessing_info.pkl', 'wb') as f:\n",
    "        pickle.dump(preprocessing_info, f)\n",
    "    \n",
    "    print(\"Processed data saved successfully!\")\n",
    "    print(\"Files saved:\")\n",
    "    print(\"X_train.npy, X_test.npy (features)\")\n",
    "    print(\"y_train.npy, y_test.npy (targets)\")\n",
    "    print(\"preprocessing_info.pkl (preprocessing objects)\")\n",
    "    \n",
    "    print(f\"\\nFinal dataset summary:\")\n",
    "    print(f\"Features: {preprocessing_info['n_features']}\")\n",
    "    print(f\"Training samples: {preprocessing_info['n_samples_train']}\")\n",
    "    print(f\"Test samples: {preprocessing_info['n_samples_test']}\")\n",
    "    print(f\"Feature names: {preprocessing_info['feature_names']}\")\n",
    "    \n",
    "else:\n",
    "    print(\"Not all variables are available for saving\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e53ce94f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: <class 'numpy.ndarray'>\n",
      "X_test: <class 'numpy.ndarray'>\n",
      "y_train: <class 'pandas.core.series.Series'>\n",
      "y_test: <class 'pandas.core.series.Series'>\n",
      "scaler: <class 'sklearn.preprocessing._data.StandardScaler'>\n",
      "imputer: <class 'sklearn.impute._base.SimpleImputer'>\n",
      "sex_encoder: <class 'sklearn.preprocessing._label.LabelEncoder'>\n",
      "\n",
      "Available: ['X_train', 'X_test', 'y_train', 'y_test', 'scaler', 'imputer', 'sex_encoder']\n",
      "Missing: []\n"
     ]
    }
   ],
   "source": [
    "required_vars = ['X_train', 'X_test', 'y_train', 'y_test', 'scaler', 'imputer', 'sex_encoder']\n",
    "available_vars = []\n",
    "missing_vars = []\n",
    "\n",
    "for var in required_vars:\n",
    "    if var in locals():\n",
    "        available_vars.append(var)\n",
    "        print(f\"{var}: {type(locals()[var])}\")\n",
    "    else:\n",
    "        missing_vars.append(var)\n",
    "        print(f\"{var}: not available\")\n",
    "\n",
    "print(f\"\\nAvailable: {available_vars}\")\n",
    "print(f\"Missing: {missing_vars}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b8ed980c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved successfully!\n",
      "Files saved:\n",
      "   - X_train.npy, X_test.npy (features)\n",
      "   - y_train.npy, y_test.npy (targets)\n",
      "   - preprocessing_info.pkl (preprocessing objects)\n",
      "\n",
      "Final dataset summary:\n",
      "   - Features: 12\n",
      "   - Training samples: 492\n",
      "   - Test samples: 123\n",
      "   - Feature names: ['Age', 'ALB', 'ALP', 'ALT', 'AST', 'BIL', 'CHE', 'CHOL', 'CREA', 'GGT', 'PROT', 'sex_encoded']\n"
     ]
    }
   ],
   "source": [
    "os.makedirs('../data/processed', exist_ok=True)\n",
    "\n",
    "y_train_np = y_train.values if hasattr(y_train, 'values') else y_train\n",
    "y_test_np = y_test.values if hasattr(y_test, 'values') else y_test\n",
    "\n",
    "np.save('../data/processed/X_train.npy', X_train)\n",
    "np.save('../data/processed/X_test.npy', X_test)\n",
    "np.save('../data/processed/y_train.npy', y_train_np)\n",
    "np.save('../data/processed/y_test.npy', y_test_np)\n",
    "\n",
    "preprocessing_info = {\n",
    "    'scaler': scaler,\n",
    "    'imputer': imputer,\n",
    "    'sex_encoder': sex_encoder,\n",
    "    'feature_names': list(X.columns),\n",
    "    'n_features': X.shape[1],\n",
    "    'n_samples_train': len(y_train),\n",
    "    'n_samples_test': len(y_test)\n",
    "}\n",
    "\n",
    "with open('../data/processed/preprocessing_info.pkl', 'wb') as f:\n",
    "    pickle.dump(preprocessing_info, f)\n",
    "\n",
    "print(\"Processed data saved successfully!\")\n",
    "print(\"Files saved:\")\n",
    "print(\"   - X_train.npy, X_test.npy (features)\")\n",
    "print(\"   - y_train.npy, y_test.npy (targets)\")\n",
    "print(\"   - preprocessing_info.pkl (preprocessing objects)\")\n",
    "\n",
    "print(f\"\\nFinal dataset summary:\")\n",
    "print(f\"   - Features: {preprocessing_info['n_features']}\")\n",
    "print(f\"   - Training samples: {preprocessing_info['n_samples_train']}\")\n",
    "print(f\"   - Test samples: {preprocessing_info['n_samples_test']}\")\n",
    "print(f\"   - Feature names: {preprocessing_info['feature_names']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06390f42",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    " **Data preprocessing completed successfully!**\n",
    "\n",
    "**What we accomplished:**\n",
    "1.  Loaded raw hepatitis C dataset\n",
    "2.  Cleaned data and created binary target (Healthy vs Hepatitis C)\n",
    "3.  Handled missing values using median imputation\n",
    "4.  Encoded categorical variable (Sex)\n",
    "5.  Scaled numerical features using StandardScaler\n",
    "6.  Split data into train/test sets (80/20)\n",
    "7.  Saved processed data and preprocessing objects\n",
    "\n",
    "**Next steps:**\n",
    "ðŸ‘‰ Run notebook `03-model-training.ipynb` to train the neural network model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HEPATITIS_C_MODEL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
